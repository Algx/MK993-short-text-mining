{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to TF-IDF and Document Comparisons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "import nlp_utilities as mytools  # this is our files of utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Multiple Files -- Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on to document comparisons, we need to be able to read in multiple files.  Use the new utility we introduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       " 'data/movie_reviews/positive/cv671_tok-10077.txt',\n",
       " 'data/movie_reviews/positive/cv672_tok-12350.txt',\n",
       " 'data/movie_reviews/positive/cv673_tok-6552.txt',\n",
       " 'data/movie_reviews/positive/cv674_tok-11591.txt',\n",
       " 'data/movie_reviews/positive/cv675_tok-11864.txt',\n",
       " 'data/movie_reviews/positive/cv676_tok-19999.txt',\n",
       " 'data/movie_reviews/positive/cv677_tok-11867.txt',\n",
       " 'data/movie_reviews/positive/cv678_tok-24352.txt',\n",
       " 'data/movie_reviews/positive/cv679_tok-13972.txt',\n",
       " 'data/movie_reviews/positive/cv680_tok-18142.txt',\n",
       " 'data/movie_reviews/positive/cv681_tok-28559.txt',\n",
       " 'data/movie_reviews/positive/cv682_tok-21593.txt',\n",
       " 'data/movie_reviews/positive/cv683_tok-12295.txt',\n",
       " 'data/movie_reviews/positive/cv684_tok-10367.txt',\n",
       " 'data/movie_reviews/positive/cv685_tok-11187.txt',\n",
       " 'data/movie_reviews/positive/cv686_tok-22284.txt',\n",
       " 'data/movie_reviews/positive/cv687_tok-20347.txt',\n",
       " 'data/movie_reviews/positive/cv688_tok-10047.txt',\n",
       " 'data/movie_reviews/positive/cv689_tok-8825.txt',\n",
       " 'data/movie_reviews/positive/cv690_tok-23617.txt',\n",
       " 'data/movie_reviews/positive/cv691_tok-11491.txt',\n",
       " 'data/movie_reviews/positive/cv692_tok-24295.txt',\n",
       " 'data/movie_reviews/positive/cv693_tok-16307.txt',\n",
       " 'data/movie_reviews/positive/cv694_tok-18628.txt',\n",
       " 'data/movie_reviews/positive/cv695_tok-12873.txt',\n",
       " 'data/movie_reviews/positive/cv696_tok-10835.txt',\n",
       " 'data/movie_reviews/positive/cv697_tok-29325.txt',\n",
       " 'data/movie_reviews/positive/cv698_tok-27735.txt',\n",
       " 'data/movie_reviews/positive/cv699_tok-10425.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytools.get_filenames(\"data/movie_reviews/positive/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = mytools.get_filenames(\"data/movie_reviews/positive/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF (Term Frequency, Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most analysis of documents for text mining and machine learning do not consider the order of words important. (The possible exceptions are sentiment analysis over \"time\" and parsing that analyses the tree structure of sentences for parts of speech and entity identification.)  Analysis of words in texts, using just the tokens, not the order, are called **\"bag-of-words\"** analyses.\n",
    "\n",
    "Some definitions for a smarter word-counting approach, using collections of texts:\n",
    "\n",
    "\n",
    "**Term Frequency**: Number of appearances of a word in a document (the token counts we saw already), usually as a percentage of the words\n",
    "\n",
    "**Document Frequency**: Number of documents that contain a word in a set of docs\n",
    "\n",
    "**TF-IDF** is **Term Frequency / Document Frequency**, with some extra fiddles.\n",
    "\n",
    "Example from [Manning, Raghavan, and Schuetze](http://nlp.stanford.edu/IR-book/html/htmledition/inverse-document-frequency-1.html) showing IDF of a rare term is high, in a corpus with those document frequencies for those terms:\n",
    "\n",
    "\n",
    "<img src=\"assets/doc_freq.png\">\n",
    "\n",
    "\n",
    "TF-IDF for a word and document is usually calculated as:\n",
    "\n",
    "**(Word t's frequency in the doc) * Log( Number of Docs / Number of docs that contain the word t)**\n",
    "\n",
    "However, it is usually done with a + 1 term or two.  You can consider tf-idf an information measure for document words (or \"features\") in a bag-of-words style analysis, where the order of the words doesn't matter, just the set of words. It is a **\"weight\"** for a word. Some features of TF-IDF:\n",
    "\n",
    "* If a term is very frequent in the whole document set (or corpus), it's less interesting overall and that word gets a low TF-IDF. Note this tends to suppress stopwords for you!  Stopwords are common in all texts, so they will have low scores. However, you need a lot of documents for this to work well. \n",
    "* Beware of effects of TF-IDF on small numbers of documents, it may not work as you would hope.\n",
    "* A term (or token) that is frequent in a few documents, but not in a lot, has a higher score. That word helps \"distinguish\" or characterize (or describe) those documents.\n",
    "\n",
    "See the discussion in [Manning, Raghavan, and Schuetze](http://nlp.stanford.edu/IR-book/html/htmledition/term-frequency-and-weighting-1.html), and even [more math in Wikipedia](http://en.wikipedia.org/wiki/Tf%E2%80%93idf). \n",
    "\n",
    "**You can always check to see if the implementation you use cleans stopwords or not and decide if you like that.**\n",
    "\n",
    "Some more python references:\n",
    "* [Demo using TextBlob, another lib](http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/)\n",
    "* [A version written on top of NLTK](https://github.com/yebrahim/TF-IDF-Generator)\n",
    "* [TF-IDF in gensim](http://radimrehurek.com/gensim/tutorial.html)\n",
    "* [TF-IDF in scikit-learn](http://scikit-learn.org/stable/modules/feature_extraction.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# code example from Building Machine Learning Systems with Python (Richert & Coelho) \n",
    "# - modified slightly by Lynn\n",
    "\n",
    "import math\n",
    "\n",
    "def tfidf(t, d, D):\n",
    "    # term freq is the count of term as percent of the doc's words\n",
    "    # d.count counts how many times t occurs in d.\n",
    "    tf = float(d.count(t)) / len(d) \n",
    "    # Note this version doesn't use +1 in denominator as many do.\n",
    "    idf = math.log( float(len(D)) / (len([doc for doc in D if t in doc])))\n",
    "    return tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How this works - if d is a document of tokens:\n",
    "d = [\"a\", \"b\", \"c\"]\n",
    "d.count(\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple example with letters instead of words as our tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a in doc_a 0.0\n",
      "a in doc_abc 0.0\n",
      "b in doc_abc 0.13515503603605478\n",
      "b in doc_abb 0.27031007207210955\n",
      "c in doc_abc 0.3662040962227032\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc_a = [\"a\"]\n",
    "doc_abb = [\"a\", \"b\", \"b\"]\n",
    "doc_abc = [\"a\", \"b\", \"c\"]\n",
    "# D is the collection of \"documents\"\n",
    "D = [doc_a, doc_abb, doc_abc]\n",
    "\n",
    "print(\"a in doc_a\", tfidf(\"a\", doc_a, D))   # a is in all of them\n",
    "print(\"a in doc_abc\", tfidf(\"a\", doc_abc, D)) # a is in all of them\n",
    "print(\"b in doc_abc\", tfidf(\"b\", doc_abc, D)) # b occurs only once here, but in 2 docs\n",
    "print(\"b in doc_abb\", tfidf(\"b\", doc_abb, D)) # b occurs more frequently in this doc\n",
    "print(\"c in doc_abc\", tfidf(\"c\", doc_abc, D)) # c is unique in the doc set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example using the same code, but fake tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "doc_a = nltk.word_tokenize(\"This tweet is about a cute kitten.\")\n",
    "doc_b = nltk.word_tokenize(\"This tweet is about Donald Trump.\")\n",
    "doc_c = nltk.word_tokenize(\"This tweet is John Oliver talking about Trump.\")\n",
    "doc_d = nltk.word_tokenize(\"Donald Trump said something shocking in a tweet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = [doc_a, doc_b, doc_c, doc_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'tweet', 'is', 'about', 'a', 'cute', 'kitten', '.'],\n",
       " ['This', 'tweet', 'is', 'about', 'Donald', 'Trump', '.'],\n",
       " ['This', 'tweet', 'is', 'John', 'Oliver', 'talking', 'about', 'Trump', '.'],\n",
       " ['Donald', 'Trump', 'said', 'something', 'shocking', 'in', 'a', 'tweet', '.']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This', 'tweet', 'is', 'about', 'a', 'cute', 'kitten', '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03196467471686454"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"Trump\", doc_c, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03196467471686454"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"Trump\", doc_d, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17328679513998632"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"kitten\", doc_a, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf(\"tweet\", doc_b, D) # try it in other docs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out there is a function in nltk (the main python text library) that will calculate tf-idf for us.  It lives on the TextCollection object. There is also a function in scikit-learn, the machine processing library.  We will use that in a minute.\n",
    "\n",
    "** Alert:  The functions in NLTK are much slower than in scikit-learn. If you do this on a book, you need to do it with scikit-learn instead. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here are some more functions we can use from NLTK.  \n",
    "\n",
    "def makeText_from_tokens(tokens):\n",
    "    return nltk.Text(tokens)\n",
    "\n",
    "def makeTextCollection(tokenslist):\n",
    "    # the input is a list of lists - the tokens for each doc read in\n",
    "    texts = [nltk.Text(doc) for doc in tokenslist]\n",
    "    collection = nltk.TextCollection(texts)\n",
    "    # it's useful to return both the list of texts, and the collection object\n",
    "    return collection, texts\n",
    "\n",
    "def compute_tfidfs_by_doc(filenames):\n",
    "    \"\"\" Takes a list of filenames, tokenizes, reports a dict with tf-idf scores.\"\"\"\n",
    "\n",
    "    from collections import defaultdict  # not the textcollection!\n",
    "    import nlp_utilities as nlp\n",
    "    \n",
    "\n",
    "    alltokens = []  # make a list of lists for the texts\n",
    "    textslist = nlp.load_texts_as_string(filenames) # returns a dict\n",
    "    for text in textslist.values():\n",
    "        # I'm not cleaning them so you can see how tf-idf helps\n",
    "        alltokens.append(nltk.word_tokenize(text))\n",
    "    collection, textobjs = makeTextCollection(alltokens)\n",
    "    \n",
    "    # this is where we will store our results\n",
    "    stats = [] # we are going to store data for each word and doc in a list of dictionaries\n",
    "    \n",
    "    for i, text in enumerate(textobjs):\n",
    "        # we use enumerate to give us a counter for the text number we are on.\n",
    "        for word in text.vocab().keys():  # just use the words in this text.\n",
    "            # the function tf_idf is a feature of the TextCollection object in nltk.\n",
    "            tfidfscore = collection.tf_idf(word, text)\n",
    "            tf = collection.tf(word, text) # is actually count / len(text); or percentage of text\n",
    "            count = text.count(word) # is the frequency of the word in the doc\n",
    "            if tfidfscore > 0: # i.e., the word is not in all the docs!\n",
    "                stats.append({\n",
    "                    \"word\": word,\n",
    "                    \"tfidf\": tfidfscore,\n",
    "                    \"tf\": tf,\n",
    "                    \"count\": count,\n",
    "                    \"filename\": filenames[i]\n",
    "                })\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... we need to read in a folder of files, tokenize them, and create a TextCollection from them.  Once we have a TextCollection, we can look at TF-IDF for words in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posfiles = mytools.get_filenames(\"data/movie_reviews/positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res = compute_tfidfs_by_doc(posfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'count': 3,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.010033444816053512,\n",
       "  'tfidf': 0.01614820647927191,\n",
       "  'word': 'keep'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.006738806088770116,\n",
       "  'word': 'boys'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.0023182179951837635,\n",
       "  'word': 'character'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.0023182179951837635,\n",
       "  'word': 'she'},\n",
       " {'count': 2,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.006688963210702341,\n",
       "  'tfidf': 0.001492599005446219,\n",
       "  'word': '``'},\n",
       " {'count': 2,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.006688963210702341,\n",
       "  'tfidf': 0.0012195421859127397,\n",
       "  'word': 'not'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.0018996121659061514,\n",
       "  'word': 'can'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.00011338311597217865,\n",
       "  'word': ')'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.006738806088770116,\n",
       "  'word': 'often'},\n",
       " {'count': 1,\n",
       "  'filename': 'data/movie_reviews/positive/cv670_tok-24009.txt',\n",
       "  'tf': 0.0033444816053511705,\n",
       "  'tfidf': 0.0030645174979068734,\n",
       "  'word': 'now'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas makes it much easier to deal with this data quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load dictionaries into a dataframe easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame.from_dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>filename</th>\n",
       "      <th>tf</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>data/movie_reviews/positive/cv670_tok-24009.txt</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.016148</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>data/movie_reviews/positive/cv670_tok-24009.txt</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>boys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>data/movie_reviews/positive/cv670_tok-24009.txt</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>data/movie_reviews/positive/cv670_tok-24009.txt</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>she</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>data/movie_reviews/positive/cv670_tok-24009.txt</td>\n",
       "      <td>0.006689</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>``</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count                                         filename        tf     tfidf  \\\n",
       "0      3  data/movie_reviews/positive/cv670_tok-24009.txt  0.010033  0.016148   \n",
       "1      1  data/movie_reviews/positive/cv670_tok-24009.txt  0.003344  0.006739   \n",
       "2      1  data/movie_reviews/positive/cv670_tok-24009.txt  0.003344  0.002318   \n",
       "3      1  data/movie_reviews/positive/cv670_tok-24009.txt  0.003344  0.002318   \n",
       "4      2  data/movie_reviews/positive/cv670_tok-24009.txt  0.006689  0.001493   \n",
       "\n",
       "        word  \n",
       "0       keep  \n",
       "1       boys  \n",
       "2  character  \n",
       "3        she  \n",
       "4         ``  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filename is in every row - each word has it's own row and score.\n",
    "byfile = data.groupby(\"filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's sort each subset by different values and see what we got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/movie_reviews/positive/cv670_tok-24009.txt\n",
      "      word  count\n",
      "110  movie      7\n",
      "104   they      7\n",
      "40     you      6\n",
      "29       !      6\n",
      "73    this      6\n",
      "data/movie_reviews/positive/cv671_tok-10077.txt\n",
      "        word  count\n",
      "143  douglas     10\n",
      "311       he      9\n",
      "186       ``      6\n",
      "227      has      6\n",
      "205     this      6\n",
      "data/movie_reviews/positive/cv672_tok-12350.txt\n",
      "        word  count\n",
      "399       ``      6\n",
      "479        i      6\n",
      "545  hunting      5\n",
      "366     film      4\n",
      "454     more      4\n",
      "data/movie_reviews/positive/cv673_tok-6552.txt\n",
      "    word  count\n",
      "791    (     12\n",
      "676    )     12\n",
      "593   on      9\n",
      "601  for      7\n",
      "788  are      5\n",
      "data/movie_reviews/positive/cv674_tok-11591.txt\n",
      "     word  count\n",
      "1119  rob     13\n",
      "1116   at     11\n",
      "1147   he     11\n",
      "1121  his     10\n",
      "1162  you      8\n",
      "data/movie_reviews/positive/cv675_tok-11864.txt\n",
      "      word  count\n",
      "1240    ``     39\n",
      "1507    as     15\n",
      "1211  film     12\n",
      "1427    by     11\n",
      "1451   was     11\n",
      "data/movie_reviews/positive/cv676_tok-19999.txt\n",
      "           word  count\n",
      "1760  frequency      8\n",
      "1745       this      6\n",
      "1909        you      6\n",
      "1684         ``      6\n",
      "1711          :      6\n",
      "data/movie_reviews/positive/cv677_tok-11867.txt\n",
      "     word  count\n",
      "1990   ``     26\n",
      "2016  her     14\n",
      "2272  she     12\n",
      "2301    i     10\n",
      "2140    ;      9\n",
      "data/movie_reviews/positive/cv678_tok-24352.txt\n",
      "          word  count\n",
      "2438        ``     26\n",
      "2419  jackie-o     11\n",
      "2531       her     10\n",
      "2620     lesly     10\n",
      "2571     marty     10\n",
      "data/movie_reviews/positive/cv679_tok-13972.txt\n",
      "            word  count\n",
      "2860          ``     28\n",
      "2915          --     13\n",
      "2949           i      8\n",
      "2822          on      6\n",
      "2887  eraserhead      6\n",
      "data/movie_reviews/positive/cv680_tok-18142.txt\n",
      "      word  count\n",
      "3121  chow      7\n",
      "3103   for      6\n",
      "3223    as      6\n",
      "3295   all      5\n",
      "3153   who      5\n",
      "data/movie_reviews/positive/cv681_tok-28559.txt\n",
      "      word  count\n",
      "3466     i      7\n",
      "3365  film      6\n",
      "3373   for      5\n",
      "3439  most      4\n",
      "3416  tbwp      4\n",
      "data/movie_reviews/positive/cv682_tok-21593.txt\n",
      "          word  count\n",
      "3581        on      8\n",
      "3666    murphy      7\n",
      "3765  lawrence      5\n",
      "3683        as      5\n",
      "3590       for      5\n",
      "data/movie_reviews/positive/cv683_tok-12295.txt\n",
      "      word  count\n",
      "3874    ``     40\n",
      "4104    he     25\n",
      "4219   his     14\n",
      "4150  dude     11\n",
      "4186    as     11\n",
      "data/movie_reviews/positive/cv684_tok-10367.txt\n",
      "       word  count\n",
      "4788      (     17\n",
      "4576      )     17\n",
      "4315  dogma     12\n",
      "4727    his     10\n",
      "4569  smith      9\n",
      "data/movie_reviews/positive/cv685_tok-11187.txt\n",
      "           word  count\n",
      "4926         --     40\n",
      "4822     jackie     14\n",
      "4993       film     13\n",
      "5203         as     12\n",
      "4950  tarantino     11\n",
      "data/movie_reviews/positive/cv686_tok-22284.txt\n",
      "         word  count\n",
      "5620      lee     11\n",
      "5494     arts     10\n",
      "5655  martial     10\n",
      "5524       by      9\n",
      "5677     they      8\n",
      "data/movie_reviews/positive/cv687_tok-20347.txt\n",
      "      word  count\n",
      "6010    as     17\n",
      "5759    ``     14\n",
      "5942   for     11\n",
      "5726  film     11\n",
      "5962   are     10\n",
      "data/movie_reviews/positive/cv688_tok-10047.txt\n",
      "       word  count\n",
      "6390      (     13\n",
      "6235      )     13\n",
      "6248     as     11\n",
      "6172     ``      8\n",
      "6151  bacon      6\n",
      "data/movie_reviews/positive/cv689_tok-8825.txt\n",
      "              word  count\n",
      "6646         alien     14\n",
      "6413        ripley      8\n",
      "6503           her      7\n",
      "6573             )      7\n",
      "6707  resurrection      6\n",
      "data/movie_reviews/positive/cv690_tok-23617.txt\n",
      "         word  count\n",
      "6782       ``     20\n",
      "6816       by      7\n",
      "6764     will      6\n",
      "6770    damon      6\n",
      "6904  hunting      6\n",
      "data/movie_reviews/positive/cv691_tok-11491.txt\n",
      "           word  count\n",
      "7216  louisiana     11\n",
      "7025         as      7\n",
      "6962        for      6\n",
      "7102        but      5\n",
      "7199         on      5\n",
      "data/movie_reviews/positive/cv692_tok-24295.txt\n",
      "       word  count\n",
      "7284     ``     16\n",
      "7258  grady     13\n",
      "7361   just     11\n",
      "7454     by     10\n",
      "7464    not     10\n",
      "data/movie_reviews/positive/cv693_tok-16307.txt\n",
      "        word  count\n",
      "7848     his     10\n",
      "7888      he     10\n",
      "7781    this      7\n",
      "7725     for      6\n",
      "7737  dinner      6\n",
      "data/movie_reviews/positive/cv694_tok-18628.txt\n",
      "       word  count\n",
      "8079    his     13\n",
      "8151      (      8\n",
      "7987  tribe      8\n",
      "8033      )      8\n",
      "8041     as      7\n",
      "data/movie_reviews/positive/cv695_tok-12873.txt\n",
      "      word  count\n",
      "8455    ``     14\n",
      "8400  this     14\n",
      "8503     (     13\n",
      "8234     )     13\n",
      "8194     i     12\n",
      "data/movie_reviews/positive/cv696_tok-10835.txt\n",
      "        word  count\n",
      "8561      ``      6\n",
      "8583    this      6\n",
      "8617      as      6\n",
      "8527    film      5\n",
      "8508  gibson      5\n",
      "data/movie_reviews/positive/cv697_tok-29325.txt\n",
      "         word  count\n",
      "8758  niagara      8\n",
      "8800        )      7\n",
      "8880        (      6\n",
      "8798      not      5\n",
      "8833      her      5\n",
      "data/movie_reviews/positive/cv698_tok-27735.txt\n",
      "        word  count\n",
      "8994       :      8\n",
      "8908  jackie      8\n",
      "9012       )      7\n",
      "8897    like      7\n",
      "9143       (      7\n",
      "data/movie_reviews/positive/cv699_tok-10425.txt\n",
      "      word  count\n",
      "9246    as      9\n",
      "9270   all      6\n",
      "9408   you      5\n",
      "9196    an      5\n",
      "9177  film      5\n"
     ]
    }
   ],
   "source": [
    "for group, rows in byfile:\n",
    "    print(group)\n",
    "    print(rows.sort_values(by=\"count\", ascending=False).head(5)[[\"word\", \"count\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/movie_reviews/positive/cv670_tok-24009.txt\n",
      "          word     tfidf\n",
      "78    butthead  0.045501\n",
      "99      beavis  0.045501\n",
      "21   searching  0.022750\n",
      "100         tv  0.020216\n",
      "26       wants  0.020216\n",
      "data/movie_reviews/positive/cv671_tok-10077.txt\n",
      "           word     tfidf\n",
      "143     douglas  0.049201\n",
      "168   detective  0.028932\n",
      "150        kirk  0.021803\n",
      "207       cases  0.014760\n",
      "250  connection  0.014535\n",
      "data/movie_reviews/positive/cv672_tok-12350.txt\n",
      "         word     tfidf\n",
      "545   hunting  0.029119\n",
      "492     damon  0.019807\n",
      "459  smartest  0.014629\n",
      "525   titanic  0.014629\n",
      "544  williams  0.010383\n",
      "data/movie_reviews/positive/cv673_tok-6552.txt\n",
      "        word     tfidf\n",
      "656    carry  0.034217\n",
      "625  caravan  0.027374\n",
      "616    carol  0.020530\n",
      "587  kenneth  0.020530\n",
      "577     anna  0.020530\n",
      "data/movie_reviews/positive/cv674_tok-11591.txt\n",
      "          word     tfidf\n",
      "1119       rob  0.052638\n",
      "916   fidelity  0.028343\n",
      "797     cusack  0.020245\n",
      "1023    frears  0.016196\n",
      "833       high  0.014931\n",
      "data/movie_reviews/positive/cv675_tok-11864.txt\n",
      "        word     tfidf\n",
      "1382  virgil  0.030442\n",
      "1543     amy  0.019831\n",
      "1186   sight  0.016862\n",
      "1465  kilmer  0.013837\n",
      "1229   irwin  0.011070\n",
      "data/movie_reviews/positive/cv676_tok-19999.txt\n",
      "           word     tfidf\n",
      "1760  frequency  0.046433\n",
      "1818   emmerich  0.017412\n",
      "1861     hoblit  0.017412\n",
      "1756     father  0.015717\n",
      "1884     looked  0.013864\n",
      "data/movie_reviews/positive/cv677_tok-11867.txt\n",
      "            word     tfidf\n",
      "2248        erin  0.021414\n",
      "2088  brockovich  0.017845\n",
      "2140           ;  0.012482\n",
      "2344  soderbergh  0.010707\n",
      "2016         her  0.010183\n",
      "data/movie_reviews/positive/cv678_tok-24352.txt\n",
      "          word     tfidf\n",
      "2419  jackie-o  0.040229\n",
      "2620     lesly  0.036572\n",
      "2571     marty  0.036572\n",
      "2511   fiancee  0.018286\n",
      "2727    pascal  0.014629\n",
      "data/movie_reviews/positive/cv679_tok-13972.txt\n",
      "            word     tfidf\n",
      "2887  eraserhead  0.035064\n",
      "2915          --  0.022411\n",
      "3027         via  0.011688\n",
      "3001       lynch  0.011688\n",
      "2860          ``  0.010735\n",
      "data/movie_reviews/positive/cv680_tok-18142.txt\n",
      "         word     tfidf\n",
      "3121     chow  0.040978\n",
      "3335    fuqua  0.017562\n",
      "3112       hk  0.017562\n",
      "3294  sorvino  0.013983\n",
      "3122  killers  0.013983\n",
      "data/movie_reviews/positive/cv681_tok-28559.txt\n",
      "       word     tfidf\n",
      "3416   tbwp  0.034618\n",
      "3364  smart  0.020508\n",
      "3514    bit  0.017577\n",
      "3404  blair  0.017309\n",
      "3468   ploy  0.017309\n",
      "data/movie_reviews/positive/cv682_tok-21593.txt\n",
      "          word     tfidf\n",
      "3666    murphy  0.045263\n",
      "3765  lawrence  0.021888\n",
      "3781     eddie  0.019398\n",
      "3715    claude  0.019398\n",
      "3586       ray  0.015445\n",
      "data/movie_reviews/positive/cv683_tok-12295.txt\n",
      "          word     tfidf\n",
      "4150      dude  0.024377\n",
      "4149  lebowski  0.017729\n",
      "3945   bowling  0.015513\n",
      "3889    redman  0.013917\n",
      "4037    bvoice  0.011133\n",
      "data/movie_reviews/positive/cv684_tok-10367.txt\n",
      "          word     tfidf\n",
      "4315     dogma  0.038834\n",
      "4569     smith  0.023190\n",
      "4385   bethany  0.012945\n",
      "4329      loki  0.009708\n",
      "4546  bartleby  0.009708\n",
      "data/movie_reviews/positive/cv685_tok-11187.txt\n",
      "           word     tfidf\n",
      "4926         --  0.031158\n",
      "4822     jackie  0.025028\n",
      "5117      brown  0.023766\n",
      "4950  tarantino  0.023128\n",
      "5306         mr  0.018923\n",
      "data/movie_reviews/positive/cv686_tok-22284.txt\n",
      "         word     tfidf\n",
      "5494     arts  0.031935\n",
      "5655  martial  0.031935\n",
      "5620      lee  0.029868\n",
      "5578   skills  0.012774\n",
      "5624     kung  0.012033\n",
      "data/movie_reviews/positive/cv687_tok-20347.txt\n",
      "            word     tfidf\n",
      "5754        mile  0.028522\n",
      "5738       green  0.022709\n",
      "5861      duncan  0.017826\n",
      "5778      guards  0.017826\n",
      "5889  hutchinson  0.014261\n",
      "data/movie_reviews/positive/cv688_tok-10047.txt\n",
      "          word     tfidf\n",
      "6151     bacon  0.033291\n",
      "6180    dillon  0.022194\n",
      "6276  campbell  0.016645\n",
      "6346     trash  0.016645\n",
      "6129    twists  0.013253\n",
      "data/movie_reviews/positive/cv689_tok-8825.txt\n",
      "              word     tfidf\n",
      "6646         alien  0.067830\n",
      "6413        ripley  0.038760\n",
      "6707  resurrection  0.023146\n",
      "6670        jeunet  0.019380\n",
      "6595        aliens  0.019380\n",
      "data/movie_reviews/positive/cv690_tok-23617.txt\n",
      "         word     tfidf\n",
      "6904  hunting  0.040419\n",
      "6770    damon  0.034367\n",
      "6739  affleck  0.022911\n",
      "6850      ben  0.020209\n",
      "6722      gus  0.016921\n",
      "data/movie_reviews/positive/cv691_tok-11491.txt\n",
      "              word     tfidf\n",
      "7216     louisiana  0.061434\n",
      "7017      southern  0.016755\n",
      "7147         local  0.011343\n",
      "6915  southwestern  0.011170\n",
      "6988       musical  0.011170\n",
      "data/movie_reviews/positive/cv692_tok-24295.txt\n",
      "        word     tfidf\n",
      "7258   grady  0.037662\n",
      "7501   tripp  0.020280\n",
      "7639  wonder  0.012014\n",
      "7328    boys  0.012014\n",
      "7594   james  0.010967\n",
      "data/movie_reviews/positive/cv693_tok-16307.txt\n",
      "         word     tfidf\n",
      "7728    idiot  0.033675\n",
      "7737   dinner  0.032175\n",
      "7738   pierre  0.026940\n",
      "7762   french  0.020205\n",
      "7879  matches  0.013470\n",
      "data/movie_reviews/positive/cv694_tok-18628.txt\n",
      "             word     tfidf\n",
      "7987        tribe  0.054419\n",
      "7953  krippendorf  0.040814\n",
      "7957  shelmikedmu  0.027210\n",
      "8114         kids  0.016248\n",
      "7963    professor  0.013816\n",
      "data/movie_reviews/positive/cv695_tok-12873.txt\n",
      "      word     tfidf\n",
      "8344  yeah  0.015000\n",
      "8463  hood  0.011250\n",
      "8375  grow  0.011250\n",
      "8466  7/10  0.008957\n",
      "8245  your  0.008744\n",
      "data/movie_reviews/positive/cv696_tok-10835.txt\n",
      "         word     tfidf\n",
      "8508   gibson  0.029295\n",
      "8556      tom  0.023436\n",
      "8574   ransom  0.020672\n",
      "8634   sinise  0.020672\n",
      "8705  forrest  0.017309\n",
      "data/movie_reviews/positive/cv697_tok-29325.txt\n",
      "         word     tfidf\n",
      "8758  niagara  0.086106\n",
      "8753   tunney  0.043053\n",
      "8791    marcy  0.043053\n",
      "8817   causes  0.017140\n",
      "8726   thomas  0.017140\n",
      "data/movie_reviews/positive/cv698_tok-27735.txt\n",
      "          word     tfidf\n",
      "8908    jackie  0.033012\n",
      "9118      hung  0.018286\n",
      "8995  henchmen  0.012191\n",
      "8943     fight  0.012191\n",
      "9100     scene  0.009844\n",
      "data/movie_reviews/positive/cv699_tok-10425.txt\n",
      "          word     tfidf\n",
      "9193     music  0.012067\n",
      "9306  watching  0.011456\n",
      "9231   hendrix  0.011281\n",
      "9172     bands  0.011281\n",
      "9167    joplin  0.011281\n"
     ]
    }
   ],
   "source": [
    "for group, rows in byfile:\n",
    "    print(group)\n",
    "    print(rows.sort_values(by=\"tfidf\", ascending=False).head(5)[[\"word\", \"tfidf\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, few stop words appear in the top TF-IDF scoring words, although there are some junk characters. Mainly we see the words that seem to be the most important distinguishing words for each document, such as movie name or job location (depending on the dataset we look at).  We did not clean the tokens at all!\n",
    "How would we clean the tokens too?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Using TF-IDF in Scikit-learn:  Use this one for any big documents or large collection of docs.\n",
    "\n",
    "https://buhrmann.github.io/tfidf-analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posfiles = mytools.get_filenames(\"data/movie_reviews/positive\")\n",
    "texts = mytools.load_texts_as_string(posfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 183)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, min_df=0.2, tokenizer=mytools.tokenize_clean)\n",
    "\n",
    "# this applies the vectorizer we defined to the texts!\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(texts.values()) #fit the vectorizer to texts\n",
    "\n",
    "print(tfidf_matrix.shape) # this is the size of the array of features, rows and columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x183 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 65 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = tfidf_vectorizer.get_feature_names()   # these are the words in the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'m\",\n",
       " \"'re\",\n",
       " \"'ve\",\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actually',\n",
       " 'almost',\n",
       " 'also',\n",
       " 'although',\n",
       " 'another',\n",
       " 'around',\n",
       " 'audience',\n",
       " 'away',\n",
       " 'back',\n",
       " 'based',\n",
       " 'become',\n",
       " 'begins',\n",
       " 'best']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code from https://buhrmann.github.io/tfidf-analysis.html\n",
    "\n",
    "def top_tfidf_feats(row, features, top_n=25):\n",
    "    ''' Get top n tfidf values in row and return them with their corresponding feature names.'''\n",
    "    import pandas as pd\n",
    "    topn_ids = np.argsort(row)[::-1][:top_n]\n",
    "    top_feats = [(features[i], row[i]) for i in topn_ids]\n",
    "    df = pd.DataFrame(top_feats)\n",
    "    df.columns = ['feature', 'tfidf']\n",
    "    return df\n",
    "\n",
    "def top_feats_in_doc(Xtr, features, row_id, top_n=25):\n",
    "    ''' Top tfidf features in specific document (matrix row) '''\n",
    "    row = np.squeeze(Xtr[row_id].toarray())\n",
    "    return top_tfidf_feats(row, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>however</td>\n",
       "      <td>0.391266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>seem</td>\n",
       "      <td>0.371693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>james</td>\n",
       "      <td>0.275637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>soon</td>\n",
       "      <td>0.275637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>films</td>\n",
       "      <td>0.247795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>comedy</td>\n",
       "      <td>0.225565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>seems</td>\n",
       "      <td>0.207058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>like</td>\n",
       "      <td>0.139136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>break</td>\n",
       "      <td>0.137818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lead</td>\n",
       "      <td>0.137818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature     tfidf\n",
       "0  however  0.391266\n",
       "1     seem  0.371693\n",
       "2    james  0.275637\n",
       "3     soon  0.275637\n",
       "4    films  0.247795\n",
       "5   comedy  0.225565\n",
       "6    seems  0.207058\n",
       "7     like  0.139136\n",
       "8    break  0.137818\n",
       "9     lead  0.137818"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_feats_in_doc(tfidf_matrix, features, 4, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## A row in the matrix corresponds to a document.  We can figure out which document by looking \n",
    "## back at the texts dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"krippendorf's tribe is a formula comedy . done poorly , formulaic comedies might seem to signify the downfall of american cinema . however , every now and then , one emerges , like krippendorf's tribe , that actually works . professor james krippendorf ( richard dreyfuss ) , the renowned anthropologist , is in trouble . his university gave him a hefty grant to discover a lost tribe in new guinea . however , he found . . . nothing . his wife has recently died , and he has spent the remainder of the grant money in raising his three kids : shelly ( natasha lyonne ) , mickey ( gregory smith ) and edmund ( carl michael lidner ) . tonight , he is expected to lecture on his newfound tribe . rather than break the news ( and face the consequences of misusing his funds ) , he invents a tribe : the shelmikedmu ( named after his kids ) . however , one lie begets another as he is not only required to deliver filmed proof of the shelmikedmu , but his research becomes a popular phenomenon . soon , professor krippendorf is caught up in an elaborate ruse in which he films mockumentary footage starring his children as the shelmikedmu tribal members . his efforts are hampered by the boasts of an over-eager colleague , veronica micelli ( jenna elfman ) , and the intense scrutiny of a rival anthropologist , ruth allen ( lily tomlin ) . krippendorf's tribe does seem to require a little suspension of disbelief . no one seems to question the way his field documentaries seem to be shot with multiple cameras , or that his newly discovered tribesmen have startlingly blue eyes . luckily , as the film builds momentum , that suspension of disbelief is easy to come by . though there's some mild humor in the krippendorf family trying to pass themselves off as a lost tribe , the real humor of the film is in how james gets trapped in his ever increasing snowball of lies . the double meanings to many of the shelmikedmu appearances are enjoyable , and the comic timing required for some of the film's latter scenes is superb . richard dreyfuss is terrific as the hapless professor who soon loses control of his own imaginary tribe . jenna elfman's position as a romantic lead seems a bit forced at times , but she plays the part with extreme affability . even the kids , who in films like this tend to be a bit on the precocious side , are endearing and humorous . yes , the film does veer occasionally into some rather lowbrow humor , but it has the best excuse of all : it's funny . it may not go down as an all-time classic , but it certainly delivers what you expect from a comedy : plenty of laughs . \\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(texts.values())[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_mean_feats(Xtr, features, grp_ids=None, min_tfidf=0.1, top_n=25):\n",
    "    ''' Return the top n features that on average are most important amongst documents in rows\n",
    "        indentified by indices in grp_ids. '''\n",
    "    if grp_ids:\n",
    "        D = Xtr[grp_ids].toarray()\n",
    "    else:\n",
    "        D = Xtr.toarray()\n",
    "\n",
    "    D[D < min_tfidf] = 0\n",
    "    tfidf_means = np.mean(D, axis=0)\n",
    "    return top_tfidf_feats(tfidf_means, features, top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>movie</td>\n",
       "      <td>0.111948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n't</td>\n",
       "      <td>0.107049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>like</td>\n",
       "      <td>0.064903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>two</td>\n",
       "      <td>0.053460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>first</td>\n",
       "      <td>0.050621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>characters</td>\n",
       "      <td>0.049678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>time</td>\n",
       "      <td>0.049567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>williams</td>\n",
       "      <td>0.043302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>performances</td>\n",
       "      <td>0.043216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>also</td>\n",
       "      <td>0.041393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>good</td>\n",
       "      <td>0.040971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>michael</td>\n",
       "      <td>0.040709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>films</td>\n",
       "      <td>0.040698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>little</td>\n",
       "      <td>0.040692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>way</td>\n",
       "      <td>0.040147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>show</td>\n",
       "      <td>0.040061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>james</td>\n",
       "      <td>0.039952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>life</td>\n",
       "      <td>0.039604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>would</td>\n",
       "      <td>0.039104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>much</td>\n",
       "      <td>0.038735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>character</td>\n",
       "      <td>0.038542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>music</td>\n",
       "      <td>0.038154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>however</td>\n",
       "      <td>0.038021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wife</td>\n",
       "      <td>0.037828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>people</td>\n",
       "      <td>0.036045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         feature     tfidf\n",
       "0          movie  0.111948\n",
       "1            n't  0.107049\n",
       "2           like  0.064903\n",
       "3            two  0.053460\n",
       "4          first  0.050621\n",
       "5     characters  0.049678\n",
       "6           time  0.049567\n",
       "7       williams  0.043302\n",
       "8   performances  0.043216\n",
       "9           also  0.041393\n",
       "10          good  0.040971\n",
       "11       michael  0.040709\n",
       "12         films  0.040698\n",
       "13        little  0.040692\n",
       "14           way  0.040147\n",
       "15          show  0.040061\n",
       "16         james  0.039952\n",
       "17          life  0.039604\n",
       "18         would  0.039104\n",
       "19          much  0.038735\n",
       "20     character  0.038542\n",
       "21         music  0.038154\n",
       "22       however  0.038021\n",
       "23          wife  0.037828\n",
       "24        people  0.036045"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_mean_feats(tfidf_matrix, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pandasnlp]",
   "language": "python",
   "name": "conda-env-pandasnlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
