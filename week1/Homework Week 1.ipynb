{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview: \n",
    "\n",
    "* Download a book or long text of your choice (English, unless you can get it all to work with French!), \n",
    "\n",
    "* word_punct tokenize it\n",
    "* clean out punctuation, stopwords\n",
    "* remove custom stop words that you find in the document word list, according to your judgment.  Show your work.\n",
    "* Make a word cloud with the final tokens (don't forget you need to rejoin them into a string). If you are on Windows and unable to install the wordcloud library, you can use an internet tool after you clean your text.\n",
    "* Then make a function to find parts of speech for your tokens.\n",
    "* Then a function to extract only the verbs in your text after parts of speech tagging.\n",
    "* Make a wordcloud of only the verbs.\n",
    "\n",
    "A good place to get books (in text format) is [Gutenberg.org](https://www.gutenberg.org/ebooks/).  Edit the file to remove the stuff at the beginning and end of the file that is about the legal status and is not the book, or I will take points off. Your file needs to be plain text.\n",
    "\n",
    "Plain text editors include Notepad and Notepad++ on Windows, and Sublime Text or Atom on Mac. RTF format or Word format or Pages format is not ok!! You will lose points for that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import nltk\n",
    "import string\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you do the wordcloud in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to make your wordcloud in the notebook big enough to read\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (20,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Show me reading your text file and tokenizing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Use a Counter on it to show the most common 15 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Show me removing the punctuation and stopwords from the token list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2a. Use a Counter on it to show the most common 15 words after 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Remove custom stopwords (other words you think aren't useful to show.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Make a wordcloud.  (Either use the Python package or an external tool. If it's external, add a cell saying you uploaded the image separately.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a function to find parts of speech (POS) for a text.\n",
    "\n",
    "It takes as input a list of tokens (the result of tokenizing and cleaning stopwords and punctuation).\n",
    "\n",
    "It returns a list of tuples of the word and its part of speech tag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write another function that removes tokens that are not Verbs from your POS tags list. Call it \"remove_nonverbs\".   It takes as input the POS tuples of the form (\"word\", \"POS\").\n",
    "\n",
    "Hint: check for [\"VB\", \"VBD\", \"VBG\",\"VBN\",\"VBP\",\"VBZ\"] as the tag of the token.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Now make a wordcloud of the words that are verbs only, the result of the function in 6.  You need to extract the words from the tuples (or use \"untag\").  (If you do it externally with a web tool, insert a cell explaining you uploaded the image to the dropbox.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:pandasnlp]",
   "language": "python",
   "name": "conda-env-pandasnlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
